> 原文链接：<https://www.jianshu.com/p/56d4babcc555>

`\xa0`表示不间断空白符，爬虫中遇到它的概率不可谓不小，而经常和它一同出现的还有`\u300`0、`\u2800`、`\t`等Unicode字符串。单从对`\xa0`、`\t`、`\u3000`等含空白字符的处理来说，有以下几种方法可行：

# 使用re.sub
使用正则表达式可以轻松匹配所有空白字符，它对于Unicode字符也是有效的，比如：

	>>> import re
	>>> s = 'T-shirt\xa0\xa0短袖圆领衫,\u3000体恤衫\xa0买一件\t吧'
	>>> re.sub('\s', ' ', s)
	T-shirt  短袖圆领衫, 体恤衫 买一件 吧

不过该正则表达式会对所有字符都进行统一处理，可能会与原页面展示效果有所出入。

# 使用translate方法
str对象的translate方法也是去除这些字符串的好帮手，该方法具体用法可参考Python标准库，本处使用示例如下：

	>>> inputstring = u'\n               Door:\xa0Novum    \t'
	>>> move = dict.fromkeys((ord(c) for c in u"\xa0\n\t"))
	>>> output = inputstring.translate(move)
	>>> output
	             Door:Novum     

# 利用split方法
将字符串分割再重组，这时候空白字符就会被pass掉了，不过该方法杀伤力太大，会导致所有空白消失，一定要慎用。
使用示例：

	>>> s = 'T-shirt\xa0\xa0短袖圆领衫,\u3000体恤衫\xa0买一件\t吧'
	>>> ''.join(s.split())
	T-shirt短袖圆领衫,体恤衫买一件吧

# 使用unicodedata模块
Python标准库的unicodedata模块提供了normalize方法将Unicode字符转换为正常字符，该方法可算是处理这类情况最好的方法了，它会让字符回归到我们期望看到的样子，同时不损害其它正常的空白字符，而且还能还原其它非空白字符。normalize第一个参数指定字符串标准化的方式。 NFC表示字符应该是整体组成(比如可能的话就使用单一编码)，而NFD表示字符应该分解为多个组合字符表示。Python同样支持扩展的标准化形式NFKC和NFKD，它们在处理某些字符的时候增加了额外的兼容特性。使用该方法处理\xa0等字符的示例如下：

	>>> import unicodedata
	>>> s = 'T-shirt\xa0\xa0短袖圆领衫,\u3000体恤衫\xa0买一件\t吧'
	>>> unicodedata.normalize('NFKC', s)
	T-shirt  短袖圆领衫, 体恤衫 买一件 吧

# 参考
[python中去掉字符串中的\xa0、\t、\n](python中去掉字符串中的\xa0、\t、\n "https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Fwangbowj123%2Farticle%2Fdetails%2F78061618")

[unicodedata --- Unicode 数据库 — Python 3.7.5rc1 文档](Unicode数据库—Python3.7.5rc1文档 "https://links.jianshu.com/go?to=%255Bhttps%3A%2F%2Fdocs.python.org%2Fzh-cn%2F3%2Flibrary%2Funicodedata.html%255D%28https%3A%2F%2Fdocs.python.org%2Fzh-cn%2F3%2Flibrary%2Funicodedata.html%29")

[str.translate](str.translate "https://links.jianshu.com/go?to=%255Bhttps%3A%2F%2Fdocs.python.org%2Fzh-cn%2F3%2Flibrary%2Fstdtypes.html%23str.translate%255D%28https%3A%2F%2Fdocs.python.org%2Fzh-cn%2F3%2Flibrary%2Fstdtypes.html%23str.translate%29")